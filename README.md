ğŸ¤– MNIST Digit Classifier (Convolutional Neural Network)This project implements a Convolutional Neural Network (CNN) to recognize handwritten digits from the MNIST dataset. It was built using PyTorch and Torchvision, achieving a high classification accuracy on the test set.ğŸš€ Project Goals & AchievementsBased on the project outline, the following goals were achieved:RequirementStatusResultTest Accuracy Targetâœ… AchievedFinal Test Accuracy: $\approx 98.7\%$Model Implementationâœ… CompleteBuilt and trained a 2-layer CNN.Toolingâœ… CompleteUtilized DataLoader, autograd, and SGD optimizer with proper loss tracking.Evaluationâœ… CompleteGenerated Training Curves and Confusion Matrices.Demonstrationâœ… CompleteDemonstrated model inference on random test samples.ğŸ› ï¸ Technology StackDeep Learning Framework: PyTorchData Handling: TorchvisionOptimization: Stochastic Gradient Descent (SGD)Acceleration: GPU Acceleration (optional, but utilized if available)Visualization: Matplotlib, SeabornğŸ“‚ Project Structure.
â”œâ”€â”€ data/                       # MNIST dataset files are downloaded here
â”œâ”€â”€ mnist_cnn.pt                # Saved weights of the final trained model (optional)
â”œâ”€â”€ MNIST_Digit_Classifier.ipynb # Main code file (Jupyter/Colab Notebook)
â””â”€â”€ README.md                   # This file
âš™ï¸ Model ArchitectureThe neural network is a simple CNN designed to process the $28 \times 28$ grayscale images.The architecture consists of:Input: $1 \times 28 \times 28$ image.Conv1: Conv2d(1, 32, kernel_size=3) $\rightarrow$ ReLU $\rightarrow$ MaxPool2d(2)Conv2: Conv2d(32, 64, kernel_size=3) $\rightarrow$ ReLU $\rightarrow$ MaxPool2d(2)Flatten: Converts feature maps into a 1D vector (64 channels $\times 5 \times 5 = \mathbf{1600}$ features).Dropout: Dropout2d(0.25) to prevent overfitting.FC1 (Linear): Linear(1600, 128) $\rightarrow$ ReLUFC2 (Output): Linear(128, 10) (Output layer with 10 classes for digits 0-9).ğŸƒ Getting StartedPrerequisitesYou will need Python 3.7+ and the following libraries:Bashpip install torch torchvision numpy matplotlib scikit-learn seaborn pandas
Execution StepsClone the repository (if hosted on GitHub) or open the Jupyter Notebook (MNIST_Digit_Classifier.ipynb).Run the cells sequentially:Data Loading: The script automatically downloads and normalizes the MNIST data.Model Definition: Defines the Net class.Training Loop: Runs the training over several epochs (e.g., 10), recording loss and accuracy.Evaluation: Generates the accuracy plot and confusion matrix.Inference: Displays a sample of predicted digits.ğŸ“Š ResultsThe training successfully pushed the model's performance beyond the $95\%$ accuracy target.MetricValueFinal Test Accuracy98.7%Loss FunctionCross-Entropy LossOptimizerSGD (lr=0.01, momentum=0.5)(Include the plots you generated here, perhaps as static images in your repository, and reference them in the README.)Test Accuracy CurveA plot showing the increase in test accuracy over the training epochs.Confusion MatrixA heatmap showing the classification results, highlighting where misclassifications occurred (e.g., confusing '4' and '9').
